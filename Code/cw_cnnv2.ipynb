{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cw_cnnv2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# cw_cnnv2"
      ],
      "metadata": {
        "id": "-mprQGsDA9NJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📦 Set-up "
      ],
      "metadata": {
        "id": "AudE1g7NjzP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ],
      "metadata": {
        "id": "8WAqxAViWc0N"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jXdJviG0jeKb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import time\n",
        "from google.colab import drive\n",
        "from skimage import io, transform\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms, utils\n",
        "from skimage import io, transform\n",
        "from torch.utils.data.sampler import Sampler, WeightedRandomSampler\n",
        "from sklearn import svm, metrics\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "# TODO: Fill in the Google Drive path where you uploaded the lab materials\n",
        "# Example: GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'Colab Notebooks/Lab materials 01-20210104'\n",
        "\n",
        "GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = '/content/drive/MyDrive/Computer Vision Coursework/CW_Folder_PG' \n",
        "GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n",
        "print(os.listdir(GOOGLE_DRIVE_PATH))\n",
        "\n",
        "sys.path.append('Coursework/CW_Folder_PG/Code/')"
      ],
      "metadata": {
        "id": "lfPgY0l-jlvZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a263f2e4-4689-4d87-d2f5-59be403da634"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "['.DS_Store', 'Models', 'CW_Dataset', 'Code', 'Video', 'test_functions_scratch.ipynb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify path to zipped dataset\n",
        "zip_path = os.path.join(GOOGLE_DRIVE_PATH, 'CW_Dataset/CW_Dataset.zip')\n",
        "\n",
        "# Copy it to Colab\n",
        "!cp '{zip_path}' .\n",
        "\n",
        "# Unzip it\n",
        "!yes|unzip -q CW_Dataset.zip\n",
        "\n",
        "# Delete zipped version from Colab (not from Drive)\n",
        "!rm CW_Dataset.zip"
      ],
      "metadata": {
        "id": "x39ej2Q3jnio"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadimages(root_dir, label_path):\n",
        "    \"\"\"Return an array of images and array of labels.\n",
        "\n",
        "        Args:\n",
        "            root_dir (string): Folder containing all the images.\n",
        "            label_path (string): Path to text file containing image filename and labels in this order.\n",
        "    \"\"\"\n",
        "    #import filenames and respective labels\n",
        "    df = pd.read_csv(label_path,\n",
        "                    delimiter=' ',\n",
        "                    header=None,\n",
        "                    names=['filename', 'label'])\n",
        "    df.sort_values('filename', inplace=True)\n",
        "    #import images\n",
        "    images = []\n",
        "    #!sort image folder\n",
        "    image_folder = sorted(os.listdir(root_dir))\n",
        "    #generator to extract each image path\n",
        "    images_in_folder = (file for file in image_folder if file.endswith('.jpg'))\n",
        "    count = 0 #index\n",
        "    for imagepath, imagepath_label in zip(images_in_folder, (df['filename'])):\n",
        "        count += 1 #check if filenames and filenames in labels list are equal\n",
        "        if re.findall('\\d+', imagepath) == re.findall('\\d+', imagepath_label):\n",
        "            image = io.imread(os.path.join(root_dir, imagepath))\n",
        "            images.append(image)\n",
        "        else:\n",
        "            print(f'Found unmatched image file {imagepath} and label {imagepath_label} \\\n",
        "                at index {count}')\n",
        "            pass\n",
        "\n",
        "    return np.array(images), np.array(df['label'])"
      ],
      "metadata": {
        "id": "lU4KegKtjpkx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = loadimages(\n",
        "    '/content/train',\n",
        "    '/content/labels/list_label_train.txt'\n",
        ")"
      ],
      "metadata": {
        "id": "dNa_UwlLNHv2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test, test_y = loadimages(\n",
        "    '/content/test',\n",
        "    '/content/labels/list_label_test.txt'\n",
        ")"
      ],
      "metadata": {
        "id": "4iiK3fo4t0Z6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, shuffle=True, stratify=y)"
      ],
      "metadata": {
        "id": "g8OxVTPXNVNm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DatasetTorch(Dataset):\n",
        "    #adapted from https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
        "    \"\"\"Images dataset for pytorch.\"\"\"\n",
        "\n",
        "    def __init__(self, root_dir, label_path, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the text file with *exact image filenames* and  respective labels.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        #self.labels = pd.read_csv(\n",
        "                                  #label_path,\n",
        "                                  #delimiter=' ',\n",
        "                                  #header=None,\n",
        "                                  #names=['filename', 'label']\n",
        "                                #)\n",
        "        #self.root_dir = root_dir\n",
        "        self.labels = label_path - 1\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        #self.image_path = sorted(os.listdir(root_dir))\n",
        "        #self.transform = transforms.Compose(\n",
        "                                #[transforms.Normalize(),\n",
        "                                #transforms.ToTensor()]\n",
        "                                #)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #if torch.is_tensor(idx):\n",
        "            #idx = idx.tolist()\n",
        "\n",
        "        #img_name = os.path.join(self.root_dir,\n",
        "                                #self.labels.iloc[idx, 0])\n",
        "        #image = io.imread(img_name)\n",
        "        image = self.root_dir[idx]\n",
        "        #label = self.labels.iloc[idx, 1]\n",
        "        label = self.labels[idx]\n",
        "        \n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image, label"
      ],
      "metadata": {
        "id": "D3Ib-BZZ_7Ms"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_images = DatasetTorch(X_train,\n",
        "                   y_train,\n",
        "                   transform=transforms.Compose([\n",
        "                    transforms.ToTensor(),                             \n",
        "                    transforms.Normalize([0.5752, 0.4495, 0.4012], [0.2654, 0.2422, 0.2407])                             \n",
        "                   ]\n",
        "                       \n",
        "                   ))\n",
        "\n",
        "dataloader = DataLoader(dataset_images, batch_size=32,\n",
        "                        shuffle=True, num_workers=0)\n",
        "\n",
        "dataset_images_val = DatasetTorch(X_val,\n",
        "                   y_val,\n",
        "                   transform=transforms.Compose([\n",
        "                    transforms.ToTensor(),                             \n",
        "                    transforms.Normalize([0.5752, 0.4495, 0.4012], [0.2654, 0.2422, 0.2407])                             \n",
        "                   ]\n",
        "                       \n",
        "                   ))\n",
        "\n",
        "\n",
        "test_loader = DataLoader(dataset_images_val, batch_size=32,\n",
        "                        shuffle=True, num_workers=0)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J8jEFvogdkoP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ⚛ Seting up the Convulution models"
      ],
      "metadata": {
        "id": "4ROJvjUIlWW3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1️⃣ Simple"
      ],
      "metadata": {
        "id": "ubP0NFrElfYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ConvNet1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(16*22*22, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 7)\n",
        "        # Define proportion or neurons to dropout\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16*22*22)\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "DL5CA80scsoZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2️⃣ Larger one"
      ],
      "metadata": {
        "id": "V-0uw33ymCxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet2(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ConvNet2, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                    in_channels=3,\n",
        "                    out_channels=32,\n",
        "                    kernel_size=1,\n",
        "                    stride=1,\n",
        "                    padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2))\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                    in_channels=32,\n",
        "                    out_channels=64,\n",
        "                    kernel_size=1,\n",
        "                    stride=1,\n",
        "                    padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Dropout(p=0.5))\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                    in_channels=64,\n",
        "                    out_channels=128,\n",
        "                    kernel_size=1,\n",
        "                    stride=1,\n",
        "                    padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2))\n",
        "\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                    in_channels=128,\n",
        "                    out_channels=256,\n",
        "                    kernel_size=1,\n",
        "                    stride=1,\n",
        "                    padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Dropout(p=0.5))\n",
        "        \n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                    in_channels=256,\n",
        "                    out_channels=512,\n",
        "                    kernel_size=1,\n",
        "                    stride=1,\n",
        "                    padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2))\n",
        "\n",
        "        self.fc= nn.Sequential(\n",
        "            nn.Linear(512*5*5, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4096, 1028),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(1028, 256),\n",
        "            nn.Linear(256, 7)\n",
        "                                )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "7gCpLXAQr8nC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🏃 Training Loop"
      ],
      "metadata": {
        "id": "x2tJVoCwmapx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net.eval()\n",
        "\n",
        "predictions = []\n",
        "targets = []\n",
        "\n",
        "# Run the model on some test examples\n",
        "with torch.no_grad():\n",
        "    correct, total, cumu_loss = 0, 0, 0\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        # Get logits\n",
        "        outputs = net(images)\n",
        "        # Calculate loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        cumu_loss += loss.item()\n",
        "        #Get predictions\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Save predictions\n",
        "        pred = predicted.detach().cpu().detach().numpy()\n",
        "        labels_list = labels.detach().cpu().detach().numpy()\n",
        "\n",
        "        #Flatten\n",
        "        for i in range(len(pred)):\n",
        "          predictions.append(pred[i])\n",
        "          targets.append(labels_list[i])\n",
        "            \n",
        "\n",
        "predictions, targets\n"
      ],
      "metadata": {
        "id": "C_6Sz957PsCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define evaluation function\n",
        "\n",
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "    targets = []\n",
        "    \n",
        "    # Run the model on some test examples\n",
        "    with torch.no_grad():\n",
        "        correct, total, cumu_loss = 0, 0, 0\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            # Get logits\n",
        "            outputs = model(images)\n",
        "            # Calculate loss\n",
        "            loss = criterion(outputs, labels)\n",
        "            cumu_loss += loss.item()\n",
        "            #Get predictions\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            #total += labels.size(0)\n",
        "            #correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Save predictions\n",
        "            pred = predicted.detach().cpu().detach().numpy()\n",
        "            labels_list = labels.detach().cpu().detach().numpy()\n",
        "\n",
        "            #Flatten\n",
        "            for i in range(len(pred)):\n",
        "              predictions.append(pred[i])\n",
        "              targets.append(labels_list[i])\n",
        "            \n",
        "\n",
        "        return predictions, targets\n"
      ],
      "metadata": {
        "id": "YCNTTuWAA9y6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_val_loss = 100_000\n",
        "patience = 10\n",
        "max_balance = -1\n",
        "accuracy_score_epoch = []\n",
        "\n",
        "\n",
        "# Initialize model\n",
        "net = ConvNet1()\n",
        "\n",
        "# transfer network to GPU\n",
        "net.to(device)\n",
        "\n",
        "# define the loss and the optimizer\n",
        "criterion = nn.CrossEntropyLoss(weight=torch.from_numpy(weight).float().to(device))\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "for epoch in range(100):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "        # transfer data to GPU\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass ->\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # backward pass <-\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        #print(metrics.classification_report(labels.cpu(), predicted.cpu()))\n",
        "        # print statistics (loss.item() returns the mean loss in the mini-batch)\n",
        "        running_loss += loss.item()\n",
        "    #print('[%d, %5d] loss: %.3f' %\n",
        "    #(epoch + 1, i + 1, running_loss / 2000))\n",
        "    running_loss = 0.0\n",
        "\n",
        "    predictions, targets = test(net, test_loader)\n",
        "    balance_accuracy = metrics.balanced_accuracy_score(targets,\n",
        "                                                      predictions)\n",
        "    accuracy_score_epoch.append(balance_accuracy)                                                                 #val_loss += loss                                                                #val_loss = val_loss / len(trainloader)\n",
        "    if balance_accuracy > max_balance:\n",
        "    #Saving the model\n",
        "      print(f'The Balanced accuracy is {balance_accuracy}')\n",
        "      max_balance = balance_accuracy\n",
        "      best_model = torch.save(net.state_dict(), 'CNN_model.pt')\n",
        "      #print('Min loss %0.2f' % min_val_loss)\n",
        "      f1_score = metrics.f1_score(targets,\n",
        "                                  predictions,\n",
        "                                  average=None)\n",
        "      trigger_times = 0\n",
        "      #min_val_loss = val_loss\n",
        "    else: \n",
        "      trigger_times += 1\n",
        "      print(f'The Balanced accuracy is {balance_accuracy}')\n",
        "    if trigger_times >= patience:\n",
        "        print('Early stopping!\\nStart to test process.')\n",
        "        break\n",
        "\n",
        "print('Finished Training on GPU: total time in seconds =', time.time() - t0)"
      ],
      "metadata": {
        "id": "oBUIFw7o865m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d9c47aeb-b733-43dc-d7ec-eaeecf4ffdca"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Balanced accuracy is 0.48109488353732016\n",
            "The Balanced accuracy is 0.5565457468398815\n",
            "The Balanced accuracy is 0.5670918252918116\n",
            "The Balanced accuracy is 0.6236265620023332\n",
            "The Balanced accuracy is 0.594061670405828\n",
            "The Balanced accuracy is 0.5899807335835471\n",
            "The Balanced accuracy is 0.569025882148384\n",
            "The Balanced accuracy is 0.6079482457921598\n",
            "The Balanced accuracy is 0.5809682006476973\n",
            "The Balanced accuracy is 0.616154299595428\n",
            "The Balanced accuracy is 0.600399621678405\n",
            "The Balanced accuracy is 0.6009881460305065\n",
            "The Balanced accuracy is 0.593705943034246\n",
            "The Balanced accuracy is 0.598035566309585\n",
            "Early stopping!\n",
            "Start to test process.\n",
            "Finished Training on GPU: total time in seconds = 49.456464767456055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. The Simpler CONV has an accuracy 72.62729124236253% and the Larger one ~48.14663951120163% with a balanced accuracy of 0.5995134407520585% and 0.2221346742004043 respectively. However the smaller Conv has jsut one dropout layer which may make it proe to overfitting. On the other hand deeped Neural networks are prone to overfitting as well.\n",
        "\n",
        "I'll create another one which is not that deep.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mcocAcuCvHI0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Let's try the weighted random sampler. \n",
        "\n",
        "For the larger Conv : The weighted random sampler increased the accuracy to 32% and 25% balanced accuracy. That accuracy lags behind behind the first one. Suggests the model is not relialing that much on the majority class\n",
        "\n",
        "For the Simple one: Did pretty much the same with 67.12830957230143% accuracy and The Balanced accuracy is 0.5778150063329726\n",
        "\n",
        "3. Next I'll try the class weights inside the loss function:\n",
        "  For the smaller got an accuracy  of the model at 67.25050916496944% and;\n",
        "  The Balanced accuracy is 0.583481414080001\n",
        "\n",
        "  For the larger 38.90020366598778%\n",
        "The Balanced accuracy is 0.14285714285714285\n",
        "\n",
        "The class weights did not lead to that much a decrease in the average accuracy, at least for the smaller convulution network. I conjecture using class weights is better even though the total accuracy has decreased as it will probably have better generalization."
      ],
      "metadata": {
        "id": "w4zm0ssQ-qLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adapted from https://discuss.pytorch.org/t/how-to-handle-imbalanced-classes/11264/5\n",
        "class_sample_count = np.unique(y_train, return_counts=True)[1]\n",
        "y = y_train - 1\n",
        "weight = 1 / class_sample_count\n",
        "samples_weight = weight[y]\n",
        "\n",
        "samples_weight = torch.from_numpy(samples_weight)\n",
        "samples_weigth = samples_weight.double()\n",
        "sampler = WeightedRandomSampler(samples_weight, len(samples_weight), replacement=True)"
      ],
      "metadata": {
        "id": "kD--vuB0Dkt0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weighted_sampler = WeightedRandomSampler(\n",
        "    weights=samples_weights,\n",
        "    num_samples=len(y_train),\n",
        "    replacement=True\n",
        ")"
      ],
      "metadata": {
        "id": "4Eqav9EAB2uB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_images = DatasetTorch(X_train,\n",
        "                   y_train,\n",
        "                   transform=transforms.Compose([\n",
        "                    transforms.ToTensor(),                             \n",
        "                    transforms.Normalize([0.5752, 0.4495, 0.4012], [0.2654, 0.2422, 0.2407]),                              \n",
        "                   ]\n",
        "                       \n",
        "                   ))\n",
        "\n",
        "dataloader = DataLoader(dataset_images, batch_size=32,\n",
        "                         num_workers=1, sampler=sampler,pin_memory=True)"
      ],
      "metadata": {
        "id": "FP2gyqjJBffj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_images_val = DatasetTorch(test,\n",
        "                   test_y,\n",
        "                   transform=transforms.Compose([\n",
        "                    transforms.ToTensor(),                             \n",
        "                    transforms.Normalize([0.5752, 0.4495, 0.4012], [0.2654, 0.2422, 0.2407])                             \n",
        "                   ]\n",
        "                       \n",
        "                   ))\n",
        "\n",
        "test_loader = DataLoader(dataset_images_val, batch_size=32,\n",
        "                        shuffle=True, num_workers=0)\n"
      ],
      "metadata": {
        "id": "Svy3nUePuSy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net.eval()\n",
        "\n",
        "predictions = []\n",
        "targets = []\n",
        "\n",
        "# Run the model on some test examples\n",
        "with torch.no_grad():\n",
        "    correct, total, cumu_loss = 0, 0, 0\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        # Get logits\n",
        "        outputs = net(images)\n",
        "        # Calculate loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        cumu_loss += loss.item()\n",
        "        #Get predictions\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Save predictions\n",
        "        pred = predicted.detach().cpu().detach().numpy()\n",
        "        labels_list = labels.detach().cpu().detach().numpy()\n",
        "\n",
        "        #Flatten\n",
        "        for i in range(len(pred)):\n",
        "          predictions.append(pred[i])\n",
        "          targets.append(labels_list[i])\n",
        "\n",
        "    print(f\"Accuracy of the model on the {total} \" +\n",
        "          f\"test images: {100 * correct / total}%\")\n",
        "    #Get balanced accruacy\n",
        "    #Get F_score\n",
        "    #if logging:\n",
        "        #wandb.log({\"test_accuracy\": correct / total})\n",
        "\n",
        "# Save the model in the exchangeable ONNX format \n",
        "#if logging:\n",
        "  #torch.onnx.export(model, images, \"model.onnx\")\n",
        "  #wandb.save(\"model.onnx\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yv3lsxoIueD7",
        "outputId": "e1aae301-0677-4c48-cb77-89e0231ed0f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the 3068 test images: 71.77314211212516%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsPBnDw2tmnk",
        "outputId": "aa9dd060-c542-4597-887c-bb04acf2e302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.99040307, 0.99099099, 0.97183099, 0.99790576, 0.98997494,\n",
              "       0.99646643, 0.98703888])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Finished Training on GPU: total time in seconds = 102.6555826663971\n"
      ],
      "metadata": {
        "id": "-Ypcp6Rfthkp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}